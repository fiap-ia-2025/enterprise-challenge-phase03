 # FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista

<p align="center">
  <a href="https://www.fiap.com.br/">
    <img src="img/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista" border="0" width="40%" height="40%">
  </a>
</p>

---

# üì¶ Enterprise Challenge - Sprint 1
<!-- T√≠tulo do projeto: curto, claro, direto. Pode destacar o problema e a tecnologia principal -->

## üë• Grupo 44
<!-- Nome oficial do grupo, se houver. Pode usar um nome criativo tamb√©m -->

## üë®‚Äçüéì Integrantes:
- Amanda Vieira Pires (RM565045)
- Ana Gabriela Soares Santos (RM565235)
- Bianca Nascimento de Santa Cruz Oliveira (RM561390)
- Milena Pereira dos Santos Silva (RM565464)
- Nayana Mehta Miazaki (RM565045) 

## üë©‚Äçüè´ Professores:
### Tutor(a)  
-  Lucas Gomes Moreira
### Coordenador(a)  
- Andr√© Godoi

---

## üìú Descri√ß√£o do Projeto

### üß† Objetivo e Motiva√ß√£o
Este projeto tem como foco a preven√ß√£o de falhas em linhas de envase da ind√∫stria de bebidas, especificamente no setor de engarrafamento de cervejas e refrigerantes. Este segmento foi escolhido por sua natureza altamente automatizada, com produ√ß√£o cont√≠nua e volumes expressivos, em que qualquer interrup√ß√£o inesperada pode resultar em perdas significativas de insumos, produtividade e qualidade do produto final. 

As principais causas dessas falhas muitas vezes est√£o associadas a pequenas varia√ß√µes em vari√°veis operacionais como temperatura, press√£o e vibra√ß√£o, que passam despercebidas por sistemas de monitoramento tradicionais. Ao mesmo tempo, esse setor apresenta alta maturidade tecnol√≥gica e viabilidade para ado√ß√£o de solu√ß√µes digitais de predi√ß√£o e automa√ß√£o. 

Nesse contexto, o projeto prop√µe o desenvolvimento de uma solu√ß√£o digital de manuten√ß√£o preditiva, utilizando sensores simulados para monitoramento dessas vari√°veis cr√≠ticas. Os dados s√£o enviados via IoT para a nuvem, onde s√£o processados por modelos de aprendizado de m√°quina que identificam padr√µes an√¥malos. A solu√ß√£o inclui visualiza√ß√£o interativa por meio de dashboards com alertas preventivos, contribuindo para maior estabilidade operacional e pr√°ticas sustent√°veis (ESG). 
Toda a arquitetura do projeto √© implementada na nuvem (AWS), garantindo escalabilidade, colabora√ß√£o remota entre os integrantes do grupo e fidelidade a um cen√°rio de aplica√ß√£o industrial real. 

---

### ‚öôÔ∏è Simula√ß√£o com Wokwi ‚Äì Sensores e ESP32 Virtualizados 
Nesta nova vers√£o do projeto, abandonamos a gera√ß√£o de dados sint√©ticos em Python e adotamos a simula√ß√£o completa do ambiente f√≠sico via Wokwi, uma plataforma online que permite programar microcontroladores e sensores em um ambiente virtual de forma realista e interativa. 

#### Estrutura de Simula√ß√£o: 
- Microcontrolador: ESP32 (simulado), programado em C++ com base na plataforma Arduino.
- Sensores utilizados:
- DHT22: sensor de temperatura e umidade;
- MPX5700: sensor de press√£o anal√≥gica; 
- MPU6050: aceler√¥metro e girosc√≥pio para vibra√ß√£o e movimento. 

#### Funcionamento: 

- O ESP32 l√™ os dados dos sensores simulados com frequ√™ncia definida (ex: a cada 5 segundos);
- O c√≥digo embarcado processa e envia os dados via protocolo MQTT diretamente para o servi√ßo AWS IoT Core; 
- A partir do IoT Core, os dados seguem para o pipeline de processamento na nuvem, sendo armazenados em PostgreSQL via AWS RDS;
- Em seguida, os modelos de IA identificam padr√µes e emitem alertas que s√£o exibidos no dashboard Streamlit. 

#### Vantagens do uso do Wokwi:
- Evita depend√™ncia de sensores f√≠sicos durante o desenvolvimento inicial;
- Permite controle total dos cen√°rios simulados (falhas, flutua√ß√µes, ru√≠dos);
- Facilita testes de conectividade com nuvem e entendimento do ciclo completo IoT ‚Üí ML ‚Üí Visualiza√ß√£o;
- Aproxima o projeto da realidade industrial, com menor custo e alta replicabilidade pedag√≥gica. 

Essa simula√ß√£o representa fielmente o comportamento operacional da linha de envase, fornecendo dados compat√≠veis com um ambiente f√≠sico real. Tamb√©m permite uma transi√ß√£o simples para sensores reais, bastando trocar o ambiente de simula√ß√£o pelo hardware f√≠sico e manter o restante da arquitetura intacta. 

### üß† Justificativa T√©cnica
<!--
Por que essa ind√∫stria?
Por que esse problema?
Por que esse tipo de abordagem t√©cnica (simula√ß√£o, ML, dashboard)?
Qual impacto esperado? (produtividade, ESG, redu√ß√£o de falhas, etc.)
-->
#### An√°lise Estat√≠stica com R 

- A linguagem R foi incorporada ao projeto por sua excel√™ncia em an√°lise estat√≠stica e por ser amplamente explorada nas disciplinas do curso;
- √â utilizada para an√°lises descritivas e preditivas com base nos dados armazenados no PostgreSQL, por meio de scripts executados no RStudio Server hospedado em uma inst√¢ncia EC2;
- Gera relat√≥rios automatizados em PDF com gr√°ficos e insights, que s√£o salvos no Amazon S3 e disponibilizados para download via dashboard.

Trade-off: Apesar de exigir configura√ß√£o de ambiente e integra√ß√£o com outros servi√ßos AWS, R proporciona recursos robustos de regress√£o, s√©ries temporais e visualiza√ß√µes avan√ßadas que enriquecem o diagn√≥stico e compreens√£o dos dados. 

#### Banco de Dados: PostgreSQL via AWS RDS
- Banco relacional robusto, com suporte a s√©ries temporais e consultas SQL avan√ßadas;
- Integra√ß√£o fluida com Python (psycopg2, sqlalchemy) e ferramentas de visualiza√ß√£o;
- Escal√°vel e confi√°vel para cen√°rios reais, com gerenciamento simplificado na AWS. 

Trade-off: Curva de configura√ß√£o um pouco maior que SQLite ou Firebase, mas com ganhos de performance, consist√™ncia e colabora√ß√£o em nuvem. A op√ß√£o por nuvem tamb√©m evita depend√™ncia de m√°quinas locais, garantindo disponibilidade e acesso remoto por todos do grupo. 

#### Visualiza√ß√£o: Streamlit com Ploty

- Streamlit permite transformar scripts Python em apps web interativos com m√≠nimo esfor√ßo;
- Plotly ser√° usado para criar gr√°ficos din√¢micos (linhas, dispers√£o, heatmaps) com interatividade embutida;
- O dashboard mostrar√° indicadores atuais, gr√°ficos de tend√™ncia e alertas em tempo real diretamente conectados ao banco de dados.

Trade-off: Streamlit oferece agilidade, mas menos controle visual do que frameworks como Dash. A escolha por Plotly garante boa qualidade visual no Streamlit, sem exigir depend√™ncias externas. Looker, apesar de potente em visualiza√ß√£o, n√£o suporta l√≥gica embarcada de IA e simula√ß√µes din√¢micas, pois depende de dados j√° processados. Isso inviabiliza o uso em prot√≥tipos baseados em IA executada em tempo real. 

Futuramente, Dash poder√° ser explorado para criar interfaces mais sofisticadas e com navega√ß√£o personalizada, caso o projeto evolua para uso em escala. 

#### Intelig√™ncia Artificial - Detec√ß√£o de Anomalias e Padr√µes

a) Abordagem: Aprendizado N√£o Supervisionado 
Como os dados simulados n√£o possuem r√≥tulos expl√≠citos (ex: "falha" ou "normal"), adotamos aprendizado n√£o supervisionado para detectar padr√µes inesperados e agrupar comportamentos operacionais similares. A estrat√©gia √© baseada em duas abordagens complementares: 

1. Clusteriza√ß√£o com K-Means: Permite identificar diferentes perfis operacionais (ex: regimes normais de opera√ß√£o, resfriamento, aquecimento, ou pr√©-falha). Essa t√©cnica ajuda a reconhecer grupos de funcionamento consistentes e pode sinalizar quando o sistema opera fora de um desses perfis esperados. 

2. Detec√ß√£o de Anomalias com Isolation Forest: Ap√≥s o agrupamento, aplica-se o Isolation Forest para identificar pontos fora do padr√£o em rela√ß√£o ao comportamento hist√≥rico. Um dado pode pertencer a um cluster conhecido, mas ainda assim se comportar de forma isolada ‚Äî o que √© √∫til para capturar anomalias contextuais. 

A combina√ß√£o das duas abordagens amplia a capacidade do sistema em detectar desvios tanto estruturais (mudan√ßa de grupo) quanto pontuais (outliers). 

b) Modelos Selecionados (Resumo Integrado): 
No contexto do nosso pipeline de manuten√ß√£o preditiva, optamos por dois modelos principais: 

1. K-Means: Para identificar diferentes estados operacionais do processo de envase, agrupando dados de sensores em clusters. Isso permite detectar padr√µes consistentes de funcionamento e indicar desvios de comportamento. 

2. Isolation Forest: Para detectar anomalias pontuais nos dados em tempo real. Ele avalia a pontua√ß√£o de isolamento dos dados dentro de uma janela de tempo, destacando eventos fora do padr√£o operacional mesmo dentro de um cluster conhecido. 

Esses dois modelos foram escolhidos por serem eficientes, explic√°veis e compat√≠veis com os recursos computacionais dispon√≠veis em nossa infraestrutura. 

Modelos adicionais como DBSCAN e One-Class SVM poder√£o ser utilizados de forma explorat√≥ria para an√°lises futuras e refinamento dos crit√©rios de agrupamento e outlier, especialmente √† medida que aumentarmos o volume de dados e a complexidade do ambiente de simula√ß√£o ou integra√ß√£o com sensores reais. 

c) Framework e Justificativa T√©cnica: 
- O scikit-learn foi adotado por ser a biblioteca mais adequada para modelagem cl√°ssica em Python. Ele oferece suporte direto aos modelos selecionados, integra√ß√£o com pandas e excelente documenta√ß√£o. Seu uso √© ideal para projetos acad√™micos e provas de conceito, permitindo r√°pido prototipagem e visualiza√ß√£o. 

Frameworks como Keras e TensorFlow foram descartados nesta etapa por serem voltados a redes neurais profundas, mais adequadas a problemas com grande volume de dados rotulados. Eles tamb√©m requerem maior infraestrutura de processamento e complexidade desnecess√°ria neste escopo inicial. 

### üìä An√°lise Preditiva com R (Complementar √† IA) 
Embora a detec√ß√£o de anomalias e o monitoramento online sejam realizados com Python e scikit-learn, o projeto tamb√©m prev√™ uma camada complementar de an√°lise preditiva estat√≠stica com uso da linguagem R. Essa camada ser√° utilizada para: 

- Analisar tend√™ncias e padr√µes hist√≥ricos dos dados de sensores;
- Aplicar t√©cnicas de regress√£o e an√°lise de s√©ries temporais (como ARIMA ou suaviza√ß√£o exponencial);
- Gerar insights descritivos e relat√≥rios aprofundados que complementem a l√≥gica de alerta instant√¢neo. 

Essa abordagem √© especialmente relevante para valida√ß√£o cruzada dos modelos, estudos de comportamento c√≠clico de vari√°veis (ex: press√£o ao longo dos turnos) e constru√ß√£o de relat√≥rios t√©cnicos. A escolha da linguagem R se d√° pela sua robustez em an√°lise estat√≠stica e por ser amplamente explorada nas aulas do curso. 

Os scripts R ser√£o executados na nuvem, em ambiente EC2 configurado com RStudio Server, extraindo dados diretamente do banco PostgreSQL via pacotes como RPostgreSQL ou DBI, e utilizando bibliotecas como ggplot2, forecast, dplyr e tidyr para processamento e visualiza√ß√£o. 

Ao final de cada an√°lise estat√≠stica, o RStudio Server gera um relat√≥rio em formato PDF com gr√°ficos, insights e recomenda√ß√µes, que √© armazenado automaticamente no Amazon S3. Este relat√≥rio poder√° ser baixado diretamente pelo usu√°rio final atrav√©s de um bot√£o no dashboard Streamlit, facilitando o acesso a an√°lises peri√≥dicas profundas. 

Essa camada n√£o interfere diretamente no pipeline de alertas, mas atua como ferramenta de suporte anal√≠tico para validar e interpretar melhor os padr√µes encontrados pelos modelos de machine learning. A execu√ß√£o em nuvem permite automa√ß√£o, compartilhamento e persist√™ncia dos scripts de an√°lise em um ambiente escal√°vel, assim como integra√ß√£o futura com dashboards ou relat√≥rios gerados diretamente a partir do RStudio Server hospedado na AWS. 

### üîÑ Pipeline de Execu√ß√£o e Re-Treinamento 
A pipeline completa do projeto foi desenhada para funcionar de forma cont√≠nua e escal√°vel, simulando o comportamento de um sistema produtivo real: 

1. Aquisi√ß√£o dos dados:
   - O ESP32, simulado via Wokwi, coleta dados dos sensores e envia via MQTT para o AWS IoT Core. 

2. Ingest√£o e Armazenamento:
   - O AWS IoT Core envia os dados diretamente para uma fun√ß√£o AWS Lambda, que processa os dados e os insere no banco PostgreSQL (via AWS RDS). 

3. Janela de Processamento:
   - Os dados s√£o processados em janelas m√≥veis (ex: √∫ltimas 10 minutos), agregando leituras por tempo para an√°lises consistentes. 

4. Infer√™ncia com Modelo Treinado:
   - A cada nova janela, o sistema aplica o modelo salvo (.pkl) com scikit-learn, acessado a partir do Amazon S3, para calcular: 
     - O cluster de opera√ß√£o atual (via K-Means); 
     - A pontua√ß√£o de anomalia (via Isolation Forest). 
   - Se detectada anomalia, um alerta √© disparado e salvo no banco. 

5. Visualiza√ß√£o no Dashboard:
   - O Streamlit acessa diretamente o PostgreSQL e o modelo .pkl para: 
     - Apresentar os dados atuais dos sensores; 
     - Mostrar as previs√µes do modelo em tempo real; 
     - Exibir alertas e gr√°ficos interativos com Plotly. 
   - A p√°gina √© atualizada automaticamente em intervalos regulares (ex: a cada 30 segundos), usando st_autorefresh, o que permite simular um comportamento quase em tempo real com base nas atualiza√ß√µes no banco de dados. 

‚ö†Ô∏è Para contextos com alta carga de leitura ou m√∫ltiplos usu√°rios simult√¢neos, essa abordagem pode se tornar limitada. Como evolu√ß√£o futura, recomendamos migrar para um modelo com cache, streaming de dados ou dashboards reativos mais robustos (ex: Dash + Redis, Kafka ou WebSockets). 

6. Treinamento e Re-treinamento do modelo: 

   - O primeiro modelo √© treinado ap√≥s o banco PostgreSQL conter volume suficiente de dados coletados via sensores simulados. Um script Python √© executado manualmente ou por agendamento em uma inst√¢ncia EC2, com ambiente pr√©-configurado com scikit-learn, pandas e bibliotecas auxiliares. Este script:
     - Consulta os dados hist√≥ricos no PostgreSQL (ex: primeira semana de opera√ß√£o);
     - Treina o modelo inicial (K-Means + Isolation Forest);
     - Salva o arquivo .pkl gerado no Amazon S3, onde ficar√° dispon√≠vel para infer√™ncia pelo dashboard. 

   - Periodicamente (ex: 1x por semana), esse mesmo script pode ser executado novamente na EC2 para:
     - Coletar novos dados acumulados; 
     - Re-treinar os modelos com base nos dados atualizados; 
     - Substituir o arquivo .pkl no S3. 

Essa abordagem garante que o sistema continue aprendendo com os dados simulados ou reais, mantenha o modelo atualizado automaticamente e ofere√ßa um ciclo completo de coleta, an√°lise e visualiza√ß√£o inteligente com base em dados industriais. 

---

### üîî Alertas e Dashboards 

O escopo do app Streamlit contempla a visualiza√ß√£o cont√≠nua dos dados operacionais e exibi√ß√£o de alertas gerados pela IA de forma acess√≠vel e em tempo quase real. 

O modelo de IA √© executado em ambiente separado e registra os alertas diretamente no banco de dados (PostgreSQL). A aplica√ß√£o Streamlit consome essas informa√ß√µes e exibe em tempo real via dashboards: 

- Lista de alertas classificados por severidade;
- Destaques visuais no dashboard com base no timestamp e vari√°vel associada;
- Contextualiza√ß√£o da anomalia com dados hist√≥ricos da vari√°vel envolvida. 

O Streamlit n√£o realiza a infer√™ncia diretamente, mas se conecta ao banco para exibir os alertas previamente identificados pelo modelo de IA em execu√ß√£o cont√≠nua no backend. 

### üß™ Bibliotecas Python Utilizadas

| Biblioteca     | Fun√ß√£o                                                                 |
|----------------|------------------------------------------------------------------------|
| `pandas`       | Manipula√ß√£o de dados tabulares e s√©ries temporais                     |
| `numpy`        | Opera√ß√µes matem√°ticas e gera√ß√£o de distribui√ß√µes de dados             |
| `scikit-learn` | Modelagem de machine learning (K-Means, Isolation Forest, etc.)       |
| `matplotlib`   | Gera√ß√£o de gr√°ficos est√°ticos para an√°lises e relat√≥rios              |
| `seaborn`      | Visualiza√ß√µes estat√≠sticas complementares para EDA                    |
| `plotly`       | Gr√°ficos interativos utilizados dentro do dashboard Streamlit         |
| `streamlit`    | Cria√ß√£o da interface web interativa e leve                            |


---
### ‚òÅÔ∏è Infraestrutura em Nuvem (Atual)

Neste projeto, optamos por uma arquitetura 100% baseada em servi√ßos da AWS, priorizando componentes leves, acess√≠veis e sob controle do time, como `scikit-learn`, AWS Lambda, RDS, IoT Core e S3.  
A escolha por treinar e executar o modelo com `scikit-learn`, em vez de plataformas como SageMaker, foi tomada com base no escopo do projeto e na estrat√©gia de aprendizado incremental.

**Justificativa por componente:**

- **scikit-learn**: oferece leveza, interpretabilidade e integra√ß√£o direta com a l√≥gica Python usada no projeto.
- **AWS Lambda**: permite executar tarefas de ingest√£o e re-treinamento sob demanda, sem a necessidade de manter servidores ligados.
- **RDS (PostgreSQL)**: armazena com seguran√ßa os dados recebidos e processados.
- **Amazon S3**: armazena os modelos `.pkl` gerados e atualizados de forma automatizada.
- **AWS IoT Core**: recebe dados dos sensores simulados via MQTT.
- **EC2**: opcionalmente usado para hospedar o app Streamlit com dashboard interativo.

Essa infraestrutura garante escalabilidade, custo controlado e facilidade de desenvolvimento colaborativo sem depend√™ncia de dispositivos f√≠sicos ou servidores locais.

**Nuvem no Projeto Atual:**

- **EC2**: m√°quina virtual na AWS para hospedar o app Python (Streamlit), permitindo acesso remoto e compartilhado do dashboard com o time e tutores.
- **RDS (PostgreSQL)**: banco de dados gerenciado e escal√°vel para armazenamento seguro e centralizado dos dados simulados.

**Justificativa geral da nuvem**:  
A ado√ß√£o da AWS proporciona escalabilidade, colabora√ß√£o simult√¢nea, seguran√ßa de dados e simula um cen√°rio corporativo real.  
Solu√ß√µes locais exigiriam setup individual, dificultando colabora√ß√£o entre os membros do grupo e limitando o acesso aos dashboards.

## üîß Arquitetura Definida
<img alt="Arquitetura" src="./img/arquitetura.jpg" />     

## üë©‚Äçüíª Divis√£o de Responsabilidades
<!--
Tabela com nome dos integrantes e a parte do projeto pela qual foram respons√°veis:
| Etapa | Respons√°vel(es) |
|-------|-----------------|
-->
#### Nayana Mehta Miazaki ‚Äì Simula√ß√£o e Integra√ß√£o com IoT (ESP32 + Wokwi + MQTT)
**Responsabilidades:**
- Programar os sensores simulados (DHT22, MPX5700, MPU6050) no Wokwi com ESP32 em C++.
- Configurar o envio dos dados via protocolo MQTT para o AWS IoT Core.
- Documentar os testes e cen√°rios de simula√ß√£o (normal, falha, ru√≠do).
- Garantir que o ESP32 virtual gere dados compat√≠veis com o pipeline em nuvem.
- Validar integra√ß√£o e conectividade com a nuvem.

#### Ana Gabriela Soares Santos ‚Äì Pipeline na Nuvem (AWS IoT ‚Üí PostgreSQL via AWS RDS)
**Responsabilidades:**
- Configurar o AWS IoT Core para receber dados dos sensores.
- Criar fun√ß√µes para roteamento dos dados para o PostgreSQL.
- Projetar o schema do banco relacional no RDS PostgreSQL.
- Garantir seguran√ßa, escalabilidade e disponibilidade do banco.
- Implementar coleta, armazenamento e recupera√ß√£o eficiente dos dados.

#### Amanda Vieira Pires ‚Äì Modelagem de IA com Python e scikit-learn
**Responsabilidades:**
- Implementar os modelos de K-Means e Isolation Forest para detec√ß√£o de padr√µes e anomalias.
- Treinar e validar os modelos com dados simulados.
- Automatizar o salvamento do modelo (.pkl) no Amazon S3.
- Especificar gatilhos para reprocessamento via AWS Lambda.
- Documentar m√©tricas de avalia√ß√£o dos modelos e testes explorat√≥rios com DBSCAN/SVM.

#### Milena Pereira dos Santos Silva ‚Äì Visualiza√ß√£o Interativa (Streamlit + Plotly)
**Responsabilidades:**
- Desenvolver dashboard interativo com Streamlit e gr√°ficos com Plotly.
- Integrar o dashboard ao banco PostgreSQL para visualiza√ß√£o em tempo real.
- Exibir alertas, gr√°ficos de tend√™ncia e estado dos sensores.
- Gerenciar download de relat√≥rios (.pdf) gerados em R (via Amazon S3).
- Garantir UX funcional e clara para usu√°rios t√©cnicos e n√£o t√©cnicos.

#### Bianca Nascimento de Santa Cruz Oliveira ‚Äì An√°lise Estat√≠stica com R e Relat√≥rios
**Responsabilidades:**
- Criar scripts de an√°lise descritiva e preditiva com R (em EC2 com RStudio Server).
- Implementar modelos estat√≠sticos.
- Gerar relat√≥rios automatizados com gr√°ficos e interpreta√ß√µes salvos no S3.
- Validar resultados com as detec√ß√µes do sistema de IA para refor√ßo anal√≠tico.
- Atuar como ponte entre as an√°lises estat√≠sticas e o dashboard.

---

## üóÉÔ∏è Estrutura de Pastas do Projeto

```bash
enterprise-challenge-phase03/
‚îú‚îÄ‚îÄREADME                # README com racional do projeto
‚îú‚îÄ‚îÄImg/                  # Pasta com imagens
‚îÇ   ‚îú‚îÄ‚îÄ arquitetura.jpg  # Diagrama de arquitetura
```

## üîß Como Executar o Projeto
<!--
Passo a passo da execu√ß√£o:
1. Pr√©-requisitos
2. Instala√ß√£o
3. Execu√ß√£o dos scripts
4. Inicializa√ß√£o do dashboard (se houver)
Organizar em blocos de c√≥digo para facilitar.
-->
[Em constru√ß√£o]

---

## üóÇ Hist√≥rico de Vers√µes
* 1.0 - 08/05/2025 - REAM.ME e Defini√ß√£o da Arquitetura

---

## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1">
<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1">

<p>
Este reposit√≥rio segue os termos da licen√ßa 
<a href="http://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0</a>.
</p>
